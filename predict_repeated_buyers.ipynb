{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLE11_DAY = 184\n",
    "\n",
    "DIR_1 = 'data_format1/'\n",
    "DIR_2 = 'data_format2/'\n",
    "\n",
    "PATH_TRAIN = DIR_1 + 'train_format1.csv'\n",
    "PATH_TEST = DIR_1 + 'test_format1.csv'\n",
    "PATH_USER_INFO = DIR_1 + 'user_info_format1.csv'\n",
    "PATH_USER_LOG = DIR_1 + 'user_log_format1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH_TRAIN)    \n",
    "df_test = pd.read_csv(PATH_TEST) # this data has nan for the probabilities, the task is to predict the nan values. \n",
    "df_user_info = pd.read_csv(PATH_USER_INFO)\n",
    "df_user_log = pd.read_csv(PATH_USER_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  merchant_id  label\n",
      "0    34176         3906      0\n",
      "1    34176          121      0\n",
      "2    34176         4356      1\n",
      "3    34176         2217      0\n",
      "4   230784         4818      0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  merchant_id  prob\n",
      "0   163968         4605   NaN\n",
      "1   360576         1581   NaN\n",
      "2    98688         1964   NaN\n",
      "3    98688         3645   NaN\n",
      "4   295296         3361   NaN\n"
     ]
    }
   ],
   "source": [
    "print(df_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age_range  gender\n",
      "0   376517        6.0     1.0\n",
      "1   234512        5.0     0.0\n",
      "2   344532        5.0     0.0\n",
      "3   186135        5.0     0.0\n",
      "4    30230        5.0     0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_user_info.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  cat_id  merchant_id  brand_id  time_stamp  action_type\n",
      "0   328862   323294     833         2882    2661.0         829            0\n",
      "1   328862   844400    1271         2882    2661.0         829            0\n",
      "2   328862   575153    1271         2882    2661.0         829            0\n",
      "3   328862   996875    1271         2882    2661.0         829            0\n",
      "4   328862  1086186    1271         1253    1049.0         829            0\n"
     ]
    }
   ],
   "source": [
    "df_user_log.rename(columns={'seller_id' : 'merchant_id'}, inplace=True)\n",
    "print(df_user_log.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_original = df_user_log.memory_usage().sum() / 2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_log['brand_id'].fillna(0, inplace=True) #has nan values and decimals, no values equal to 0 (can use 0 as nan)\n",
    "df_user_log['time_stamp']  = (pd.to_datetime(df_user_log['time_stamp'], format='%m%d') - pd.to_datetime(df_user_log['time_stamp'].min(), format= '%m%d')).dt.days # adds uneceary year (1900) but we want the benefits of the datetime operations.\n",
    "#after we get a number of days from the earliest date in the dataset. It is just an int that is easy to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_log['user_id'] = df_user_log['user_id'].astype('int32') # reduce memory usage and speed up calculations\n",
    "df_user_log['item_id'] = df_user_log['item_id'].astype('int32')\n",
    "df_user_log['cat_id'] = df_user_log['cat_id'].astype('int16')\n",
    "df_user_log['merchant_id'] = df_user_log['merchant_id'].astype('int16')\n",
    "df_user_log['brand_id'] = df_user_log['brand_id'].astype('int16')\n",
    "df_user_log['time_stamp'] = df_user_log['time_stamp'].astype('int16')\n",
    "df_user_log['action_type'] = df_user_log['action_type'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87 GB (1.99 GB saved)\n"
     ]
    }
   ],
   "source": [
    "memory_optimized = round(df_user_log.memory_usage().sum() / 2**30,2)\n",
    "memory_saved = round((memory_original - memory_optimized), 2)\n",
    "print(f'{memory_optimized} GB ({memory_saved} GB saved)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_info['gender'].fillna(2, inplace=True) #0 for female, 1 for male, 2 and NULL for unknown.\n",
    "df_user_info['gender'] = df_user_info['gender'].astype('int8')\n",
    "df_user_info['age_range'].fillna(0, inplace=True) # 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown.\n",
    "df_user_info['age_range'] = df_user_info['age_range'].astype('int8')\n",
    "df_user_info['user_id'] = df_user_info['user_id'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for each merchant and user\n",
    "df_user_log['time_month'] = df_user_log['time_stamp'] // 30         # make a new column that represents the month\n",
    "df_user_log['time_week'] = df_user_log['time_stamp'] // 7           # make a new column that represents the week\n",
    "\n",
    "merchants = df_user_log.groupby('merchant_id')                      # Calculate total sales, number of transactions, average transaction value per merchant.\n",
    "users = df_user_log.groupby('user_id')                              # Calculate statistics per user, such as total activity duration, number of actions, etc\n",
    "merchants_users = df_user_log.groupby(['merchant_id', 'user_id'])   # Understand user behavior with specific merchants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double11 = df_user_log[df_user_log['time_stamp'] == DOUBLE11_DAY].reset_index(drop=True) # get the data for the double 11 day\n",
    "double11_merchants = double11.groupby('merchant_id') \n",
    "double11_users = double11.groupby('user_id')\n",
    "double11_merchants_users = double11.groupby(['merchant_id', 'user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unique merchant and user featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = merchants.nunique().reset_index()\n",
    "to_merge = to_merge.rename(columns={\n",
    "    'item_id': 'items_merchant', \n",
    "    'cat_id': 'categories_merchant',\n",
    "    'user_id': 'users_merchant',\n",
    "    'brand_id': 'brands_merchant',\n",
    "    'time_stamp': 'dates_merchant',\n",
    "    'time_period': 'periods_merchant',\n",
    "    'action_type': 'action_types_merchant'\n",
    "    })\n",
    "df_train = df_train.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "to_merge = users.nunique().reset_index()            # 5 minutes. summary of unique counts per user\n",
    "to_merge = to_merge.rename(columns={\n",
    "    'item_id': 'items_user', \n",
    "    'cat_id': 'categories_user',\n",
    "    'merchant_id': 'merchants_user',\n",
    "    'brand_id': 'brands_user',\n",
    "    'time_stamp': 'dates_user',\n",
    "    'time_month': 'months_user',\n",
    "    'time_week': 'weeks_user',\n",
    "    'action_type': 'action_types_user'\n",
    "})\n",
    "df_train = df_train.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "to_merge = merchants_users.nunique().reset_index()\n",
    "to_merge = to_merge.rename(columns={\n",
    "    'item_id': 'items_user_merchant', \n",
    "    'cat_id': 'categories_user_merchant',\n",
    "    'brand_id': 'brands_user_merchant',\n",
    "    'time_stamp': 'dates_user_merchant',\n",
    "    'time_period': 'periods_user_merchant',\n",
    "    'action_type': 'action_types_user_merchant'\n",
    "    })\n",
    "df_train = df_train.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "to_merge = users['action_type'].value_counts().unstack(fill_value=0)\n",
    "to_merge = to_merge.rename(columns={\n",
    "    0: 'clicks_user',\n",
    "    1: 'add_to_carts_user',\n",
    "    2: 'purchases_user',\n",
    "    3: 'add_to_favorites_user'\n",
    "})\n",
    "df_train = df_train.merge(to_merge, on='user_id', how='left')   \n",
    "\n",
    "to_merge = merchants['action_type'].value_counts().unstack(fill_value=0)\n",
    "to_merge = to_merge.rename(columns={\n",
    "    0: 'clicks_merchant',\n",
    "    1: 'add_to_carts_merchant',\n",
    "    2: 'purchases_merchant',\n",
    "    3: 'add_to_favorites_merchant'\n",
    "})\n",
    "df_train = df_train.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "to_merge = merchants_users['action_type'].value_counts().unstack(fill_value=0)\n",
    "to_merge = to_merge.rename(columns={\n",
    "    0: 'clicks_user_merchant',\n",
    "    1: 'add_to_carts_user_merchant',\n",
    "    2: 'purchases_user_merchant',\n",
    "    3: 'add_to_favorites_user_merchant'\n",
    "})\n",
    "df_train = df_train.merge(to_merge, on=['user_id', 'merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ratio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "\n",
    "# ratio of actions from a merchant perspective\n",
    "df_train['clicks_in_user_ratio'] = df_train['clicks_user_merchant'] / (df_train['clicks_merchant'] + EPS)\n",
    "df_train['carts_in_user_ratio'] = df_train['add_to_carts_user_merchant'] / (df_train['add_to_carts_merchant'] + EPS)\n",
    "df_train['purchases_in_user_ratio'] = df_train['purchases_user_merchant'] / (df_train['purchases_merchant'] + EPS)\n",
    "df_train['favourites_in_user_ratio'] = df_train['add_to_favorites_user_merchant'] / (df_train['add_to_favorites_merchant'] + EPS)\n",
    "\n",
    "# ratio of actions from a user perspective\n",
    "df_train['clicks_in_merchant_ratio'] = df_train['clicks_user_merchant'] / (df_train['clicks_user'] + EPS)\n",
    "df_train['carts_in_merchant_ratio'] = df_train['add_to_carts_user_merchant'] / (df_train['add_to_carts_user'] + EPS)\n",
    "df_train['purchases_in_merchant_ratio'] = df_train['purchases_user_merchant'] / (df_train['purchases_user'] + EPS)\n",
    "df_train['favourites_in_merchant_ratio'] = df_train['add_to_favorites_user_merchant'] / (df_train['add_to_favorites_user'] + EPS)\n",
    "\n",
    "# ratio of action types for every merchant\n",
    "df_train['temporary_total_actions_merchant'] = (df_train['clicks_merchant'] + df_train['add_to_carts_merchant'] + df_train['purchases_merchant'] + df_train['add_to_favorites_merchant'] + EPS)\n",
    "df_train['clicks_ratio_merchant'] = df_train['clicks_merchant'] / (df_train['temporary_total_actions_merchant'])\n",
    "df_train['carts_ratio_merchant'] = df_train['add_to_carts_merchant'] / (df_train['temporary_total_actions_merchant'])\n",
    "df_train['purchases_ratio_merchant'] = df_train['purchases_merchant'] / (df_train['temporary_total_actions_merchant'])\n",
    "df_train['favourites_ratio_merchant'] = df_train['add_to_favorites_merchant'] / (df_train['temporary_total_actions_merchant'])\n",
    "df_train.drop('temporary_total_actions_merchant', axis=1, inplace=True)\n",
    "\n",
    "# ratio of action types for every user\n",
    "df_train['temporary_total_actions_user'] = (df_train['clicks_user'] + df_train['add_to_carts_user'] + df_train['purchases_user'] + df_train['add_to_favorites_user'] + EPS)\n",
    "df_train['clicks_ratio_user'] = df_train['clicks_user'] / (df_train['temporary_total_actions_user'])\n",
    "df_train['carts_ratio_user'] = df_train['add_to_carts_user'] / (df_train['temporary_total_actions_user'])\n",
    "df_train['purchases_ratio_user'] = df_train['purchases_user'] / (df_train['temporary_total_actions_user'])\n",
    "df_train['favourites_ratio_user'] = df_train['add_to_favorites_user'] / (df_train['temporary_total_actions_user'])\n",
    "df_train.drop('temporary_total_actions_user', axis=1, inplace=True)\n",
    "\n",
    "# ratio of action types for every user-merchant pair\n",
    "df_train['temporary_total_actions_user_merchant'] = (df_train['clicks_user_merchant'] + df_train['add_to_carts_user_merchant'] + df_train['purchases_user_merchant'] + df_train['add_to_favorites_user_merchant'] + EPS)\n",
    "df_train['clicks_ratio_user_merchant'] = df_train['clicks_user_merchant'] / (df_train['temporary_total_actions_user_merchant'])\n",
    "df_train['carts_ratio_user_merchant'] = df_train['add_to_carts_user_merchant'] / (df_train['temporary_total_actions_user_merchant'])\n",
    "df_train['purchases_ratio_user_merchant'] = df_train['purchases_user_merchant'] / (df_train['temporary_total_actions_user_merchant'])\n",
    "df_train['favourites_ratio_user_merchant'] = df_train['add_to_favorites_user_merchant'] / (df_train['temporary_total_actions_user_merchant'])\n",
    "df_train.drop('temporary_total_actions_user_merchant', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interval feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = (users['time_stamp'].max() - users['time_stamp'].min()).rename('action_interval')\n",
    "df_train = df_train.merge(to_merge, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicting "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
